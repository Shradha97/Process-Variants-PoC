{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize the data\n",
    "\n",
    "* Read data from prep\n",
    "* Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CaseFeatures\n",
    "### Simple7\n",
    "\n",
    "CASE | TASK | FIRST_TS | LAST_TS | ACTIVITY_COUNT | DISTINCT_ACTIVITY_COUNT |TASK_SWITCHES\n",
    "---- | ---- | -------- | ------- | -------------- | ------------- |  -------------\n",
    "C1   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C1   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C2   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C2   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C3   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C3   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C3   | T4   | 0        | 0       | 1              | 1             |0\n",
    "C4   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C4   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C4   | T4   | 0        | 0       | 1              | 1             |0\n",
    "C5   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C5   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C5   | T3   | 0        | 0       | 1              | 1             |0\n",
    "C6   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C6   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C6   | T3   | 0        | 0       | 1              | 1             |0\n",
    "C7   | T1   | 0        | 0       | 1              | 1             |0\n",
    "C7   | T2   | 0        | 0       | 1              | 1             |0\n",
    "C7   | T3   | 0        | 0       | 1              | 1             |0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from configs.config import cache as cache_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign input and output data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file_name = \"activities.csv\"\n",
    "out_file_name = \"features.csv\"\n",
    "out_path = cache_path + out_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read activities json into pandas dataframe\n",
    "def read_json_to_df(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# read activities csv into pandas dataframe\n",
    "activities_df = pd.read_csv(cache_path + in_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_switches(lst):\n",
    "    switch_counts = defaultdict(int)\n",
    "    last_seen = {}\n",
    "\n",
    "    for i, elem in enumerate(lst):\n",
    "        if elem not in last_seen:\n",
    "            last_seen[elem] = (elem, i)\n",
    "            continue\n",
    "\n",
    "        prev_elem, _ = last_seen[elem]\n",
    "        if prev_elem != lst[i - 1]:\n",
    "            switch_counts[elem] += 1\n",
    "\n",
    "        last_seen[elem] = (elem, i)\n",
    "\n",
    "    unique_elements = set(lst)\n",
    "    for elem in unique_elements:\n",
    "        if elem not in switch_counts:\n",
    "            switch_counts[elem] = 0\n",
    "\n",
    "    return switch_counts\n",
    "\n",
    "def featurize(activities_df):\n",
    "    # sort the case tasks by timestamp\n",
    "    activities_df = (activities_df.groupby(['case', 'task'])\n",
    "                 .apply(lambda x: x.sort_values('event_time'))\n",
    "                 .reset_index(drop=True)\n",
    "                )\n",
    "    \n",
    "    # add activity_count and distinct_activity_count columns and processing_time column\n",
    "    activities_df[\"activity_count\"] = activities_df.groupby(['case', 'task'])['activity'].transform('count')\n",
    "    activities_df[\"distinct_activity_count\"] = activities_df.groupby(['case', 'task'])['activity'].transform('nunique')\n",
    "    activities_df[\"processing_time\"] = activities_df.groupby(['case', 'task'])['processing_time'].transform('sum')\n",
    "    activities_df.drop(columns='activity', inplace=True)\n",
    "    # activities_df = (\n",
    "    #     activities_df.assign(\n",
    "    #         activity_count=activities_df.groupby(['case', 'task'])['activity'].transform('count'),\n",
    "    #         distinct_activity_count=activities_df.groupby(['case', 'task'])['activity'].transform('nunique'),\n",
    "    #         processing_time=activities_df.groupby(['case', 'task'])['processing_time'].transform('sum'),\n",
    "    #     )\n",
    "    #     .drop(columns='activity')\n",
    "    # )\n",
    "\n",
    "    # keep the row with the first activity for each case-task combination\n",
    "    activities_df.drop_duplicates(subset=['case', 'task'], keep='first', inplace=True)\n",
    "\n",
    "    # add task_switch column\n",
    "    switch_counts_per_case_df = (\n",
    "        activities_df.groupby('case')['task']\n",
    "        .apply(lambda x: count_switches(x.tolist()))\n",
    "        .to_frame()\n",
    "        .reset_index()\n",
    "        .rename(columns={'task': 'task_switch', 'level_1': 'task'})\n",
    "    )   \n",
    "\n",
    "    # drop rows with NaN values in the TASK_SWITCH column\n",
    "    switch_counts_per_case_df.dropna(inplace=True)\n",
    "    switch_counts_per_case_df.reset_index(drop=True, inplace=True)\n",
    "    switch_counts_per_case_df.head()\n",
    "\n",
    "    # merge the 2 dataframes on CASE and TASK\n",
    "    activities_df = pd.merge(activities_df, switch_counts_per_case_df, on=['case', 'task'])\n",
    "\n",
    "    # add first_ts and last_ts columns\n",
    "    activities_df = (\n",
    "        activities_df.assign(\n",
    "            FIRST_TS=activities_df.groupby(['case', 'task'])['event_time'].transform('min'),\n",
    "            LAST_TS=activities_df.groupby(['case', 'task'])['event_time'].transform('max')\n",
    "        )\n",
    "        .drop(columns='event_time')\n",
    "    )\n",
    "\n",
    "    # keep only the first task - case combination\n",
    "    # activities_df.drop_duplicates(subset=['case', 'task'], keep='first', inplace=True)\n",
    "\n",
    "    # convert first_ts and last_ts columns to datetime\n",
    "    activities_df[['FIRST_TS', 'LAST_TS']] = activities_df[['FIRST_TS', 'LAST_TS']].apply(pd.to_datetime)\n",
    "\n",
    "    # rename columns\n",
    "    activities_df.rename(columns={'FIRST_TS': 'first_TS', 'LAST_TS': 'last_TS'}, inplace=True)\n",
    "\n",
    "    return activities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize the data and export to features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter activities_df to only include cases with values not equal to 'Missing' or 0\n",
    "activities_df = activities_df.query('case != \"Missing\" and case != \"0\" and case != \"None\"')\n",
    "\n",
    "final_df = featurize(activities_df)\n",
    "final_df.to_csv(cache_path + out_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show final_df as a pivot table\n",
    "# final_df.pivot_table(\n",
    "#     index='case', \n",
    "#     columns='task', \n",
    "#     values='activity_count', \n",
    "#     aggfunc='count', \n",
    "#     fill_value=0, \n",
    "#     margins=True).astype(int).sort_values('All', ascending=False, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
